Malware is dangerous, but not always obviously so. If malware was easy to detect, then every email, network, or sharing system would have complete protection. As cybersecurity tools evolve, so too should the ease at which all kinds of malicious content detected and removed. Yet in 2020, McAfee’s Center for Strategic and International Studies reported a record global loss of just under one trillion dollars. So why is malware still so effective in the modern era of cybersecurity?\n\nDesigned to assimilate with our natural expectations, some malware cleverly evades audits and analysis tools. Apparently normal email, website, and free online tools all provide doorways for bad actors to inject malicious code, programs, or processes to facilitate their goals.\n\nMalicious intent disguised to take advantage of an individual’s better nature has always been an effective strategy. As an analogy, areas with armed conflict will use landmines to disguise an innocuous road into a dangerous trap. We can think of evasive malware much in the same way.\n\nIf we view the road and see a disturbed patch of dirt or a beeping metal detector, we can determine what we have found, making the path safe for travel. But sometimes we don’t know. Landmines can be buried carefully or made of non-metallic components effectively preventing our attempts at discovery.\n\nThe safest way through is to detonate our path in advance.\n\nAs early as World War II, massive rotating flails were attached to large, shielded vehicles to slam the ground and detonate mines to make a safe path through minefields. Similarly designed vehicles are still used today. This method is violent and expensive, yet controlled, calculated, and extremely effective.\n\nModern cybersecurity tools, like sandbox analysis, allow us to detonate malware in much the same way. Sample programs and files are loaded into isolated and secured virtual environments where malware can run, but not harm any outside system. The malware sample is our landmine, and the sandbox our heavily armored flail.\n\nWith the detonation of code, we can analyze every aspect of the content and verify its intent. The file might be safe, or it may attempt to contact unverified external sources, change registry keys, or scan the local file system. Running malware in an isolated environment to analyze its behavior is known as dynamic analysis.\n\nUnlike our road, which has the binary condition of safe or not safe, we need to consider the complexity of a file’s intent. Many legitimate programs will perform actions that fall into potentially malicious activity. Not every sandbox is created equal, and what makes a good product are the methods and calculations used to provide the highest possible certainty when analyzing a file’s activity.\n\nSandboxing is not, however, an end-all solution to malware. To not contaminate the results, each file must be scanned on an individual basis. It takes a significant amount of time and hardware resources to process even a single PDF, installer, executable, or other file type, which can bottleneck security systems when dealing with large quantities of files. Knowing when and under what circumstances to use a sandbox, is paramount to making this a truly effective technology in your data flow


n obvious flaw when considering the effectiveness of static analysis practices is the fact that without exact matches of previously defined factors that classify a file or code sample as malicious, hackers can bypass traditional signature matching software by making slight alterations to their malware. Previously, when an antivirus company finds a malicious file, they updated their AV signature database. Then, all the endpoints and security systems that received that update would recognize the infected file. This method worked fine when malware was less common, but with today’s circumstances of thousands of malware programs being released daily, analysis and updates from AV companies to update their definitions is becoming less and less effective. To help balance the scale against hackers, AV companies have introduced a technique known as heuristic analysis to aid in detecting polymorphic malware designed to evade traditional signature-based detection systems.Heuristic analysis works by decompiling a file or program and inspecting its source code. Like signature definition databases, a heuristic system has its own heuristics database matching decompiled source code, with the source code of known malware to look for matching elements. In this way even if a malware file has been changed to avoid a traditional AV static scan, the heuristic scan will detect the matching elements and flag the file as malware.  The techniques used to match the source code content can be an incredibly effective method for catching malware designed to evade traditional signature matching, as source code typically is much harder to alter without making changes to the malware’s original intended purpose. Heuristic scanning is not infallible, nor is it a perfect solution. One of the biggest challenges with heuristic scanning is the fact that since only a portion of the composition of a file is observed for a malware match, the risk of a false positive is significantly increased.Now that we know how heuristic scans work, we have a better understanding of when to use, and when to trust a heuristic analysis result

most security solutions are implemented into existing systems with their own task dependencies and responsibilities. For example, the primary purpose of a job application service website is to manage resumes, cover letters and communications between hiring managers and job candidates. However, since anyone in the world can submit PDFs and other documents to HR departments using this service, this could pose as an easy entry vector for malicious actors targeting specific companies. Therefore, the best place to implement malware scanning solutions is to work directly in-line with processes such as this. A well deployed malware solution should only be noticed once a detection has been made, and not hinder the systems it has been integrated with. In-line scanning works well, as it can be deployed at various layers of segmentation within an internal network, and levels of file and program scrutiny can be tuned and tightened accordingly. Remember, the types of malware techniques we deploy are heavily dependent on the type of data we expect, and the volume in question. With this in mind, let’s look at some other techniques we can use with an in-line security approach to protect our users and defend against all manner of attacks. Click the Static Analysis icon to learn about the first. You will be able to proceed after viewing them all


By now we are familiar with the concept that no single security solution can cover all the aspects of securing our critical networks. The best approach is to use several solutions to cover many aspects of security in critical network data flows. Security companies know this, and they strive to create methods of integration not only with the flow of data, but also with other security solutions. When multiple security solutions are used for a single data entry point or logical data workflow process, it’s referred to as a security stack.Most security implementations follow a hand-off approach, where data is provided to a system, usually for scanning or file alteration, then provided back to the workflow. Data is presented in it's raw, copied, or adapted form, and then sent to another system to process the information and provide a result.Sometimes in-line data might be part of a security solution, but the notification mechanisms that occur upon detection follow a more retroactive approach. For example, file data might be sent to a sandbox as an auxiliary or secondary scanning tool, where waiting for files doesn’t make sense for the workflow. In these instances, systems need to be able to programmatically track and notify proper parties and systems after the secondary detection.The question becomes, how do security systems interact with existing data flows, and with each other? Luckily, there are several standardized methods of enabling data hand-off. Out-Of-The-BoxSeveral security software companies develop a large breadth of technologies, tools, deployable appliances, and solutions. These companies have various products that, because they are in-house, are designed to work seamlessly with one another and to connect with the push of a button, or other simple connections. The actual technical backend of out-of-the-box integrations can vary, but the point is for security administrators who purchase the products to have a solution that just works. Additionally, some vendors have very strong technical partnerships and work closely with each other to create seamless integrations with another companies’ solution. Out-of-the-box integrations are the most difficult to create, but when done properly are preferable to hiring many cyber security professionals to do the same job. Standardized ProtocolsAs Hypertext Transfer Protocol (HTTP) and Simple Mail Transfer Protocol (SMTP) [see glossary for more information on HTTP, SMTP, HTTPS, API, and ICAP] are standardized protocols for web traffic and email transfer respectively, there are several protocols created to specifically enable easy security hand-offs for scanning or other processes. A great example for this is ICAP, or Internet Content Adaption Protocol. ICAP is a standardized, lightweight protocol designed to offload cybersecurity tasks onto specialized servers to evaluate network throughput. This is a method of sidebar communication between network appliances. What makes ICAP extremely useful is most web proxy solutions can communicate ICAP, and therefore easily hand-off network traffic for scanning. Many cyber security vendors leverage standardized protocols such as this to allow for seamless integration into other systems. APIAPI, or Application Programming Interface, is a programmatic interface that allows software systems to communicate with other software systems. APIs only expose necessary information, actions, and specified parts of a system, thus preventing exposure of the interworking of the software code from connecting systems. A perhaps overly simplified but useful analogy is thinking of a drive-through window at a fast-food restaurant. You are presented a list of possible options, and you make your request. You don’t watch the food being prepared, but your order will be provided to you at the window regardless. If you make a request out of the scope of the menu, the restaurant will not comply. And if you make too many orders per second, you’re probably not going to get very far. You need to make your order within the parameters of the drive-through.API’s for many systems have a list of available calls that can be requested. Security systems use APIs to send and receive all kinds of information and can be used to integrate with other solutions built in-house, by establishing a programmatic connection.  WebhookIn our example of a secondary sandbox solution that retroactively sends a detection notification, the information sends to additional security systems, or for administrative notifications, often occurs in the form of a Webhook. Webhooks send data, usually over HTTP or Hypertext Transfer Protocol Secure (HTTPS) trigger events. In the case of the sandbox detection when the file finished the dynamic scan and was flagged as malicious. Webhooks are not used explicitly for retroactive actions and can easily be used as a real-time communication method with in-line solutions. With cyber security solutions, they function as an excellent method to trigger reactive detection response event procedures

While we always want to cover all areas of vulnerably, there are potential pitfalls when dealing with implementing large security stacks into our data workflows. Increased security can often come at the cost of increased complexity, and the more moving pieces there are, the higher the likelihood of a potential failure. Therefore, it’s imperative that when any new solution is introduced to a secure environments, proper testing and validation is completed before moving to a production environment. Ideally, the various solutions will have a common compatibility certificate, as seen with various vendors and their technical alliances. As with any other proper implemented critical IT solutions, high availably, scaling, and contingency plans are all important when architecting a security solution or stack, if a single system goes down, consider how that effects the other systems in an overall workflow, where the bottlenecks are, and ultimately how to minimize downtime in the event of a downed system. With proper analysis and planning, you can run a secure environment, with excellent uptime

Static analysis works well in almost all circumstances, especially in high-volume environments like Amira’s. However, it is not effective protection against unknown threats such as zero day vulnerabilities

Heuristic analysis should run along with the AV engine and is a good fit for Amira’s \nsituation. This type of scan will help her identify malware which has changed its \ncharacteristics, but it can result in many false positives.

Dynamic analysis works well in low-volume, highly critical environments when transfers are not time-sensitive. This is probably not the optimal approach for Amira, but it can and should be used to help identify suspected files

Dynamic Analysis – Dynamic analysis involves isolating and running files in a sandbox environment. This works well in low-volume, highly critical environments when transfers are not time-sensitive. It uses a lot of computing resources to analyze each file, but it's a great way to determine what an unknown malware file would do should it be exposed to your critical files, and it will help you to spot the latest malware variants falling victim to them. This is probably not the optimal approach for Amira, but it can and should be used to help identify suspected files that may contain malware, especially to test and validate potential false positives. Her research complete, she must now make a final decision.

The Dynamic Host Configuration Protocol (DHCP) is a network management protocol used on Internet Protocol (IP) networks for automatically assigning IP addresses and other communication parameters to devices connected to the network using a client–server architecture.

The execution of malware in a sandbox or VM to monitor its run-time behaviors. Unlike static analysis, dynamic analysis is immune to code obfuscation.
dynamic analysis assigns a threat score base on the

Advanced Threat Protection (ATP) is a suite of analysis tools designed to defend against advanced threats that use known and unknown attack vectors. ATP augments more common security solutions aimed at repelling known intrusion strategies.

Advanced threats are those that seek to surreptitiously gain access to a network and remain, undetected, in that network for months or even years, exfiltrating large amounts of data, conducting espionage, and/or causing significant 



Content Disarm & Reconstruction is a computer security technology for removing potentially malicious code from files. Unlike malware analysis, CDR technology does not determine or detect malware's functionality but removes all file components that are not approved within the system's definitions and policies. It is used to prevent cyber security threats from entering a corporate network perimeter. Channels that CDR can be used to protect include email and website traffic. Advanced solutions can also provide similar protection on computer endpoints, or cloud email and file sharing services. There are three levels of CDR

Encryption is an important tool but is not sufficient alone to ensure the security or privacy of sensitive information throughout its lifetime. Most applications of encryption protect information only at rest or in transit, leaving sensitive data in clear text and potentially vulnerable to improper disclosure during processing, such as by a cloud service for example. Homomorphic encryption and secure multi-party computation are emerging techniques to compute on encrypted data; these techniques are general but incur high computational and/or communication costs. In response to encryption of data at rest, cyber-adversaries have developed new types of attacks. These more recent threats to encryption of data at rest include cryptographic attacks, stolen ciphertext attacks, attacks on encryption keys, insider attacks, data corruption or integrity attacks, data destruction attacks, and ransomware attacks. Data fragmentation and active defense data protection technologies attempt to counter some of these attacks by distributing, moving or mutating ciphertext so it is more difficult to identify, steal, corrupt, or destroy

It is also possible to classify IDS by detection approach. The most well-known variants are signature-based detection (recognizing bad patterns, such as malware) and anomaly-based detection (detecting deviations from a model of "good" traffic, which often relies on machine learning). Another common variant is reputation-based detection (recognizing the potential threat according to the reputation scores). Some IDS products have the ability to respond to detected intrusions. Systems with response capabilities are typically referred to as an intrusion prevention system. Intrusion detection systems can also serve specific purposes by augmenting them with custom tools, such as using a honeypot to attract and characterize malicious traffic.


An Internet protocol that exchanges network packets between a client and server through a proxy server.  SOCKS5 (SOCKS version 5) optionally provides authentication so only authorized users may access a server. Practically, a SOCKS server proxies TCP connections to an arbitrary IP address, and provides a means for UDP packets to be forwarded. SOCKS performs at Layer 5 of the OSI model (the session layer, an intermediate layer between the presentation layer and the transport layer). A SOCKS server accepts incoming client connection on TCP port 1080, as defined in RFC 1928.

Static analysis is excellent at scanning large volumes of files, but relies on predetermined signatures of already known threats


Heuristic scanning adds additional protection against polymorphic malware, but can potentially flag more false positives due to analyzing smaller individual parts of a file’s source code

hacker target are Ip PPi Finatial data and distrupt in continity of services
malware scan perimeter

lost or stolen PPI can cause 
Lawsuite
lost of confidence
lost of business
fines for organization

threat are parvasive because
1 hacker create new threat
2. the increase in compleaxity cyber space crate open for exploite
3. few cyber professional
4. general public are poorly educated


SandBox lool at
Os resources
imported dll
portable exceutable
access atempt 
risky flie

